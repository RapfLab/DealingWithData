{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rebeccarafp/Documents/RapfLabPython/DLS/210617/CorrFunctions\n",
      "['210616OOApost.csv', '210612OICApost.csv', '210610OVApost.csv', '210615OBApost.csv', '210610OVApost_2.csv', '210616OOApre.csv', '210612OICApre.csv', '210610OVApre.csv', '210615OBApre.csv']\n",
      "210616OOApost.csv\n",
      "210612OICApost.csv\n",
      "210610OVApost.csv\n",
      "210615OBApost.csv\n",
      "210610OVApost_2.csv\n",
      "210616OOApre.csv\n",
      "210612OICApre.csv\n",
      "210610OVApre.csv\n",
      "210615OBApre.csv\n"
     ]
    }
   ],
   "source": [
    "#DLSProcessing\n",
    "#Adapting old DLS python scripts for UTSA data and RapfLab generally\n",
    "#Rebecca Rapf\n",
    "#June 24, 2021\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "#import datetime\n",
    "#Note -- if you change anything in the DLSFunctionLibrary code, you need to close and \n",
    "#re-initialize this notebook for it to update\n",
    "import DLSFunctionLibrary as DFL\n",
    "\n",
    "\n",
    "Path0 = '/Users/rebeccarafp/Documents/RapfLabPython/DLS/210617/CorrFunctions/'\n",
    "#SAVE_DATA = 'yes'\n",
    "SAVE_DATA = 'yes'\n",
    "FileType = \"csv\"\n",
    "DLSType = \"UTSA\"\n",
    "\n",
    "##### CONSTANTS -- specific for each DLS Instrument/experimental set up #####\n",
    "TEMP = 298 #K\n",
    "LASER = 640 #nm\n",
    "VISC = 1 #cP\n",
    "####################\n",
    "AvgRadii = pd.DataFrame(index = [\"Avg\",\"Std\",\"AvgR2\"])\n",
    "\n",
    "os.chdir(Path0)\n",
    "print(os.getcwd())\n",
    "\n",
    "#Make the output folder if it does not already exist\n",
    "outputfolder = \"Fitted\"\n",
    "isdir = os.path.isdir(outputfolder)\n",
    "if isdir == False:\n",
    "    os.mkdir(outputfolder)\n",
    "    \n",
    "#Read in all files of a given file type\n",
    "ListFiles = sorted(glob.glob(\"*\"+FileType))\n",
    "ListFiles.sort(key=os.path.getmtime)\n",
    "print(ListFiles)\n",
    "\n",
    "\n",
    "#Read in all files\n",
    "for entry in range(len(ListFiles)):\n",
    "    \n",
    "    p_file = ListFiles[entry]\n",
    "    print(p_file)\n",
    "    \n",
    "    #strip out name of experiment\n",
    "    prename = p_file[:-(len(FileType)+1)]\n",
    "    #print(prename)\n",
    "\n",
    "    if DLSType == \"UTSA\":\n",
    "        [data,num_meas] = DFL.ReadUTSA(p_file)\n",
    "    else:\n",
    "        print(\"You need to use a different program that can read data for a diff DLS\")\n",
    "\n",
    "    \n",
    "    #Initializing the parameters for fitting function -- takes temperature in Kelvin \n",
    "    #and laser wavelength in nm as arguments\n",
    "    modelParamsDict = DFL.initializeExponentialModelParams(TEMP,LASER,VISC);\n",
    "    #print(modelParamsDict)\n",
    "    \n",
    "    \n",
    "    #Initializing for Normalizing Correlation Functions ###\n",
    "    \n",
    "    ###Check if correlation functions are already normalized ####\n",
    "    if  0.99 <= data.iloc[:,1][1:25].mean() <= 1.1:\n",
    "        print(\"Already Normalized\")\n",
    "        #NormData = data\n",
    "        print(data.iloc[:,1][1:25].mean())\n",
    "    else:\n",
    "        NormData = pd.DataFrame()    \n",
    "        SumNormCorr = np.zeros(len(data))\n",
    "        SumUnNormCorr = np.zeros(len(data))\n",
    "        SumNormAvg = 0\n",
    "    \n",
    "        for entry in range(num_meas):\n",
    "            if entry == 0:\n",
    "                if DLSType == \"UTSA\":\n",
    "                    NormData[prename+\"DecayTime\"] = data.iloc[:,0]/1000 #convert to ms\n",
    "            #print(CleanedData)\n",
    "\n",
    "            CopyArray =  data.iloc[:,entry+1]\n",
    "            NormAvg = CopyArray[1:25].mean()\n",
    "        #print(NormAvg)\n",
    "            NormCopyArray = CopyArray.div(NormAvg)\n",
    "            NormData[prename+\"Corr\"+str(entry)] = NormCopyArray\n",
    "        #print(NormData.iloc[:,1][1:25].mean())\n",
    "\n",
    "            SumNormAvg += NormAvg\n",
    "\n",
    "            SumUnNormCorr += CopyArray\n",
    "            SumNormCorr += NormCopyArray  \n",
    "\n",
    "        AvgNormCorr = SumNormCorr/num_meas\n",
    "\n",
    "        AvgUnNormCorr = SumUnNormCorr/SumNormAvg\n",
    "\n",
    "        NormData[prename+\"AvgNormCorr\"] = AvgNormCorr\n",
    "        NormData[prename+\"AvgUnNormCorr\"] = AvgUnNormCorr\n",
    "    \n",
    "        NormData.to_csv(\"Norm/\"+prename+'CleanCorr.csv')\n",
    "    \n",
    "    #Initialize data frames and array for fitting process\n",
    "    FitArray = pd.DataFrame()\n",
    "    R2Array = np.zeros(num_meas)\n",
    "    RadiiArray = np.zeros(num_meas)\n",
    "    RadVarArray = np.zeros(num_meas)\n",
    "    RadStdArray = np.zeros(num_meas)\n",
    "    \n",
    "    #IndexNames = range(num_meas-2)#+[\"AvgNormCorr:\",\"AvgUnNormCorr\"]\n",
    "    #print(IndexNames)\n",
    "    #print(NormData.head())\n",
    "    \n",
    "    for entry in range(num_meas):\n",
    "        #print(entry)\n",
    "        Decays = NormData.iloc[:,0]#/1000 #units needs to be in ms. Plate Reader Data is in us.\n",
    "        #print(Decays)\n",
    "        \n",
    "        Corr = NormData.iloc[:,entry+1]\n",
    "        #print(Corr)\n",
    "        CurrName = NormData.columns[entry+1]\n",
    "    \n",
    "        modelParamsDict[\"DecayTime\"] = Decays\n",
    "        #print AvgData.iloc[:,i]\n",
    "        Radius, RadVar = curve_fit(DFL.ExponentialModel, modelParamsDict, Corr, maxfev = 100000)\n",
    "        #print(Radius)\n",
    "        RadiiArray[entry] = Radius\n",
    "        RadVarArray[entry] = RadVar\n",
    "        RadStdArray[entry] = np.sqrt(RadVar)\n",
    "        #print(RadiiArray)\n",
    "    \n",
    "        FitArray['Fit'+CurrName] = (DFL.ExponentialModel(modelParamsDict,Radius))\n",
    "    #    \n",
    "        R0 = np.sum((DFL.ExponentialModel(modelParamsDict,Radius) - Corr)**2)\n",
    "    #    #print AvgR0\n",
    "        R1 = np.sum((Corr - np.mean(Corr))**2)\n",
    "        R2 = 1 - (R0/R1)\n",
    "        R2Array[entry] = R2\n",
    "        \n",
    "        #print(R2)\n",
    "    \n",
    "    ExtractedRadii = pd.DataFrame()#index = IndexNames)\n",
    "    \n",
    "    ExtractedRadii[prename+'Radii']=RadiiArray\n",
    "    ExtractedRadii[prename+'RadVar']=RadVarArray\n",
    "    ExtractedRadii[prename+'RadStd']=RadStdArray\n",
    "    ExtractedRadii[prename+'R2']=R2Array\n",
    "    #\n",
    "    #print(ExtractedRadii)\n",
    "    \n",
    "    AvgRadii[prename+\"AvgRadii\"] = [RadiiArray.mean(),RadiiArray.std(),R2Array.mean()]\n",
    "    #print(AvgRadii)\n",
    "    #AvgRadii[prename+\"AvgRadiiStd\"] = []\n",
    "    #print(AvgRadiiStd)\n",
    "    \n",
    "    if SAVE_DATA == 'yes':\n",
    "        FitArray.to_csv(\"./\"+outputfolder+\"/\"+prename+'Fits.csv')\n",
    "        ExtractedRadii.to_csv(\"./\"+outputfolder+\"/\"+prename+'Radii.csv')\n",
    "    else:\n",
    "        print(\"DATA WAS NOT SAVED\")\n",
    "if SAVE_DATA == \"yes\":\n",
    "    AvgRadii.to_csv(\"./\"+outputfolder+\"/\"+\"SummaryRadii.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
